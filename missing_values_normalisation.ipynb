{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/dermatology.data', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[33].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(265)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/dermatology2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# les types de données de chaque colonne\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lire la dernière colonne\n",
    "lis = (df.iloc[:, -2].unique().tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le pourcentage de valeurs manquantes dans chaque colonne\n",
    "missing_percentage = get_missing_pourcentage_column(df[33])\n",
    "\n",
    "# Afficher le pourcentage de valeurs manquantes dans chaque colonne\n",
    "print(missing_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot an histogram of the  last column\n",
    "df.iloc[:, -2].hist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition des fonctions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_values_column(column, list_missing_values):\n",
    "    \"\"\"Return the missing values of a column\"\"\"\n",
    "    return column[column.isin(list_missing_values)]\n",
    "    \n",
    "def get_missing_pourcentage_column(column : pd.Series):\n",
    "    \"\"\"Return the pourcentage of missing values of a column\n",
    "            the missing values for this method is np.nan\"\"\"\n",
    "    return column.isna().mean() * 100\n",
    "\n",
    "def replace_missing_values_column_by_nan(column : pd.Series, list_missing_values):\n",
    "    \"\"\"Replace the missing values of a column by np.nan\"\"\"\n",
    "    column.replace(list_missing_values, np.nan, inplace=True)\n",
    "    # column = pd.Series(list(column.replace(list_missing_values, np.nan))).astype(np.float64)\n",
    "\n",
    "\n",
    "def replace_missing_values_column_by_mode(column : pd.Series, list_missing_values):\n",
    "    \"\"\"Replace the missing values of a column by the mode\"\"\"\n",
    "    mode = column.mode()[0]\n",
    "    column.replace(list_missing_values, mode, inplace=True)\n",
    "\n",
    "def replace_missing_values_column_by_mean(column : pd.Series, list_missing_values):\n",
    "    \"\"\"Replace the missing values of a column by the mean\"\"\"\n",
    "    mean = column.mean()\n",
    "    column.replace(list_missing_values, mean, inplace=True)\n",
    "    \n",
    "def replace_missing_values_column_by_mediane(column : pd.Series, list_missing_values):\n",
    "    \"\"\"Replace the missing values of a column by the mediane\"\"\"\n",
    "    mediane = column.median()\n",
    "    column.replace(list_missing_values, mediane, inplace=True)\n",
    "\n",
    "def replace_missing_values_column_by_value(column : pd.Series, list_missing_values, value): \n",
    "    \"\"\"Replace the missing values of a column by a value\"\"\"\n",
    "    column.replace(list_missing_values, value, inplace=True)\n",
    "\n",
    "#TODO: faire une fonction qui remplace les valeurs manquantes par prediction\n",
    "\n",
    "def replace_missing_values_column_by_prediction(column : pd.Series, list_missing_values, model):\n",
    "    \"\"\"Replace the missing values of a column by the prediction of the model\"\"\"\n",
    "    pass\n",
    "\n",
    "def normalize_column_by_min_max(column: pd.Series):\n",
    "    \"\"\"Normalize a column by the min max method\n",
    "        La normalisation Min-Max : cette méthode consiste à transformer les données \n",
    "        en une plage de valeurs entre 0 et 1. La formule de normalisation est la suivante :\n",
    "        X_norm = (X - X_min) / (X_max - X_min)\n",
    "        Où X est la valeur originale, X_min et X_max sont respectivement les valeurs minimale et maximale \n",
    "        de l'ensemble de données. Cette méthode est utile lorsque les données ont une plage de valeurs connue et délimitée.\n",
    "    \"\"\"\n",
    "\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    import numpy as np\n",
    "\n",
    "    # Exemple de données à normaliser\n",
    "    # data = np.array([[10, 2], [5, 3], [8, 7]])\n",
    "\n",
    "    # Créer un objet scaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Normaliser les données\n",
    "    data_norm = scaler.fit_transform(column.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "    column.replace(column.values, data_norm, inplace=True)\n",
    "\n",
    "def normalize_column_by_standardization(column : pd.Series):\n",
    "    \"\"\"Normalize a column by the standardization method (z score)\n",
    "        La normalisation standard : cette méthode consiste à transformer les données en une distribution normale \n",
    "        avec une moyenne de 0 et un écart-type de 1. La formule de normalisation est la suivante :\n",
    "\n",
    "        X_norm = (X - moyenne) / écart-type\n",
    "\n",
    "        Où X est la valeur originale, la moyenne et l'écart-type sont calculés à partir de l'ensemble de données. \n",
    "        Cette méthode est utile lorsque les données ont une distribution normale ou presque normale.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    import numpy as np\n",
    "\n",
    "    # Exemple de données à normaliser\n",
    "    # data = np.array([[10, 2], [5, 3], [8, 7]])\n",
    "\n",
    "    # Créer un objet scaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Normaliser les données\n",
    "    data_norm = scaler.fit_transform(column.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "    column.replace(column.values, data_norm, inplace=True)\n",
    "\n",
    "def normalize_column_by_boxcox(column : pd.Series):\n",
    "    \"\"\"Normalize a column by the boxcox method\n",
    "    La transformation de Box-Cox utilise une fonction puissance pour ajuster la distribution des données \n",
    "    à une distribution normale. La transformation est définie par une équation de la forme :\n",
    "\n",
    "    y' = (y^lambda - 1) / lambda, si lambda différent de 0\n",
    "    y' = log(y), si lambda = 0\n",
    "\n",
    "    où y est la variable à transformer, y' est la variable transformée, et lambda est un paramètre \n",
    "    qui peut prendre n'importe quelle valeur réelle. La valeur optimale de lambda pour une variable \n",
    "    donnée est celle qui maximise la log-vraisemblance de la distribution transformée.\n",
    "    \"\"\"\n",
    "    \n",
    "    from scipy import stats\n",
    "    \n",
    "    # Exemple de données à normaliser\n",
    "    # data = np.array([[10, 2], [5, 3], [8, 7]])\n",
    "\n",
    "    # Normaliser les données\n",
    "    data_norm, _ = stats.boxcox(column.values)\n",
    "\n",
    "    column.replace(column.values, data_norm, inplace=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour vous aider à choisir la méthode la plus approprié à votre cas, nous vous recomondons de prendre en compte certains indicateurs: \n",
    "* L'écart type: est une mesure de la dispersion qui indique la variabilité des données autour de la moyenne. Plus l'écart type est grand, plus les données sont dispersées.\n",
    "\n",
    "* Plage interquartile : La plage interquartile est la différence entre le troisième quartile (Q3) et le premier quartile (Q1) de la distribution. Elle représente la plage de valeurs qui contient la moitié des données. Une plage interquartile large indique une forte dispersion des données.\n",
    "\n",
    "* Étendue : L'étendue est la différence entre la valeur maximale et la valeur minimale dans la distribution. Une grande étendue peut indiquer une forte dispersion des données.\n",
    "\n",
    "* Variance : La variance est une mesure de la dispersion qui indique la variabilité des données par rapport à leur moyenne. Une variance élevée indique une forte dispersion des données."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test des fonctions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creer un dataframe avec des entiers en incluant les valeurs manquantes\n",
    "df_test = pd.DataFrame(np.random.randint(0, 100, size=(100, 4)), columns=list('ABCD'))\n",
    "\n",
    "# Ajouter des valeurs manquantes\n",
    "df_test.loc[0, 'A'] = '?'\n",
    "df_test.loc[1, 'A'] = 'none'\n",
    "df_test.loc[0, 'C'] = 'None'\n",
    "df_test.loc[1, 'B'] = '?'   \n",
    "df_test.loc[2, 'C'] = '?'\n",
    "df_test.loc[3, 'D'] = '?'\n",
    "\n",
    "# Afficher le dataframe\n",
    "df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[3].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_column_by_min_max(df[33])\n",
    "df[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = df_test['A'].mean()\n",
    "mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_missing_values = ['?', 'None', 'NaN', 'nan', 'Nan', 'NAN', 'none', '']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_v = get_missing_values_column(df_test['C'], list_missing_values)\n",
    "list_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = df[33].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_missing_values_column_by_nan(df[33], list_missing_values)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df_test.columns:\n",
    "    replace_missing_values_column(df_test[column], list_missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.dtypes  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d32378c0dae322513b1bb240c9466d0aa923b931e69055e65cd3a9c36e69821"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
